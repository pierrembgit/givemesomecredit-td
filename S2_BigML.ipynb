{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On importe la librairie bigml\n",
    "from bigml.api import BigML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On se connecte à bigml\n",
    "api = BigML(project='project/5d94a32e42129f2e16000232')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On crée une source à partir du csv\n",
    "source_train = api.create_source('storage/source_dataset_train_full.csv')\n",
    "source_test = api.create_source('storage/source_dataset_test.csv')\n",
    "api.ok(source_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On crée un dataset à partir de la source puis on split (DATASET de TRAIN)\n",
    "dataset_train_full = api.create_dataset(source_train, {\"name\": \"Dataset Train Full\"})\n",
    "api.ok(dataset_train_full)\n",
    "dataset_train_train = api.create_dataset(dataset_train_full, {\"name\": \"Dataset Train Train\", \"sample_rate\": 0.8, \"seed\": \"my seed\"})\n",
    "api.ok(dataset_train_train)\n",
    "dataset_train_test = api.create_dataset(dataset_train_full, {\"name\": \"Dataset Train Test\", \"sample_rate\": 0.8 , \"seed\": \"my seed\", \"out_of_bag\": True})\n",
    "api.ok(dataset_train_test)\n",
    "\n",
    "# On crée un dataset à partir de la source (DATASET de TEST)\n",
    "dataset_test = api.create_dataset(source_test, {\"name\": \"Dataset Test\"})\n",
    "api.ok(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On lance un ensemble\n",
    "ensemble = api.create_ensemble(dataset_train_train, {\"objective_field\" : \"SeriousDlqin2yrs\", \"name\": \"Ensemble\"})\n",
    "api.ok(ensemble)\n",
    "ensemble_full = api.create_ensemble(dataset_train_full, {\"objective_field\" : \"SeriousDlqin2yrs\", \"name\": \"Ensemble Full\"})\n",
    "api.ok(ensemble_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On lance un batch sur le dataset TEST\n",
    "batch_prediction = api.create_batch_prediction(ensemble_full, dataset_test, {\"name\": \"Batch Prediction\", \"output_fields\": [\"Id\"], \"probabilities\": True})\n",
    "# On vérifie le bon fonctionnement du batch\n",
    "api.ok(batch_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On lance un batch sur le dataset Train de validation\n",
    "batch_prediction_all_fields = api.create_batch_prediction(ensemble, dataset_train_test, {\"name\": \"Batch Prediction All Fields\", \"prediction_name\" : \"SeriousDlqin2yrs_Predic\", \"all_fields\": True, \"probabilities\": True,})\n",
    "# On vérifie le bon fonctionnement du batch\n",
    "api.ok(batch_prediction_all_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On récupère le ROC AUC via une évaluation\n",
    "evaluation = api.create_evaluation(ensemble, dataset_train_test)\n",
    "api.ok(evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On récupère le ROC AUC via une évaluation\n",
    "evaluation_full = api.create_evaluation(ensemble_full, dataset_train_test)\n",
    "api.ok(evaluation_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AUC = 0.85628\n",
      " AUC = 0.86857\n"
     ]
    }
   ],
   "source": [
    "# On affiche l'AUC depuis l'évaluation\n",
    "#api.pprint(evaluation['object']['result'])\n",
    "AUC = evaluation['object']['result']['model']['average_area_under_roc_curve']\n",
    "print(f\" AUC = {AUC}\")\n",
    "\n",
    "AUC = evaluation_full['object']['result']['model']['average_area_under_roc_curve']\n",
    "print(f\" AUC = {AUC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'storage/my_evaluation.json'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On télécharge les csv du batch et des datasets ainsi que le json de l'évaluation\n",
    "api.download_batch_prediction(batch_prediction, filename='storage/batch_prediction.csv')\n",
    "api.download_batch_prediction(batch_prediction_all_fields, filename='storage/batch_prediction_all_fields.csv')\n",
    "api.download_dataset(dataset_train_full, filename='storage/dataset_train_full.csv')\n",
    "api.download_dataset(dataset_train_train, filename='storage/dataset_train_train.csv')\n",
    "api.download_dataset(dataset_train_test, filename='storage/dataset_train_test.csv')\n",
    "api.download_dataset(dataset_test, filename='storage/dataset_test.csv')\n",
    "api.export(evaluation, filename='storage/my_evaluation.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
